{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7bf060d8-972d-4116-8ad8-157e075af1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,Flatten,Embedding, SimpleRNN,LSTM\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import random\n",
    "import pickle as pk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize, LineTokenizer , regexp_tokenize\n",
    "import string\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "231d8255-9cc6-4232-8479-a8486d84bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "source= [\n",
    "    ['What is the capital of Egypt?', 'Cairo'],\n",
    "    ['What is the capital of Sudan?', 'Khartoum'],\n",
    "    ['What is the capital of Zambia?', 'Lusaka'],\n",
    "    ['What is the capital of Libya?', 'Tripoli'],\n",
    "    ['What is the capital of Somalia?', 'Mogadishu'],\n",
    "    ['What is the capital of Morocco?', 'Rabat'],\n",
    "    ['What is the capital of Kenya?', 'Nairobi'],\n",
    "    ['What is the capital of Nigeria?', 'Abuja'],\n",
    "    ['What is the capital of Tanzania?', 'Dodoma'],\n",
    "    ['How many players in Football (soccer) ?', '11 players on each team (10 field players and 1 goalkeeper)'],\n",
    "    ['How many players in Volleyball ?', '6 players on each team (3 front-row players and 3 back-row players)'],\n",
    "    ['How many players in Basketball ?', '5 players on each team'],\n",
    "    ['How many players in Tennis ?', '1 player on each side of the court (singles) or 2 players on each side (doubles)'],\n",
    "    ['How many players in Baseball ?', '9 players on each team (1 pitcher, 1 catcher, 4 infielders, and 3 outfielders)'],\n",
    "    ['How many players in Hockey ?', '6 players on each team (1 goalie and 5 skaters)'],\n",
    "    ['How many players in Rugby ?', '15 players on each team'],\n",
    "    ['What is the ambulance number in Egypt ?', '123'],\n",
    "    ['What is the Police number in Egypt ?', '122'],\n",
    "    ['What is the number of Tourist Police in Egypt ?', '126'],\n",
    "    ['What is the Natural Gas Emergency number in Egypt ?', '129'],\n",
    "    ['What is the number of Traffic Police in Egypt ?', '128'],\n",
    "    ['What is the largest organ in the human body ?', 'The Skin'],\n",
    "    ['Diabetes affects the body’s ability to produce which hormone ?', 'Insulin'],\n",
    "    ['A cardiologist is a doctor who specialises in conditions affecting which organ ?', 'The heart'],\n",
    "    ['The fibula and tibia are bones found in which body part ?', 'The leg'],\n",
    "    ['How many more bones are babies born with than are part of the adult skeleton ?', '64'],\n",
    "    ['How many bones are there in the adult body ?', '206'],\n",
    "    ['What is the name of the membranes that cover the brain and spinal cord ?', 'Meninges'],\n",
    "    ['The father of medicine, Hippocrates, theorised that the secret to health was to maintain balance between blood, phlegm, black bile and yellow bile. What term did he use to describe these four most important fluids ?', 'The four humors'],\n",
    "    ['Which two parts of the body can take over the function of the spleen if it has to be removed?', 'The liver and bone marrow'],\n",
    "    ['What is the longest river in the world ?', 'Nile River: The Nile is approximately 6,650 km (4,132 miles) long and flows through eleven countries in Africa, including Egypt, Sudan, and Ethiopia'],\n",
    "    ['What is the biggest country in the world by land area ?', 'The biggest country in the world by land area is Russia'],\n",
    "    ['What is the normal human body temperature ?', 'The normal human body temperature is typically around 36.5 to 37.5 degrees Celsius (97.7 to 99.5 degrees Fahrenheit)'],\n",
    "    ['Tell me a small description about Natural Language Processing (NLP)?',   'Natural Language Processing (NLP) is a field of study in computer science and artificial intelligence that focuses on the interaction between human language and computers. It involves developing algorithms and computational models that enable computers to understand, interpret, and generate human language.'],\n",
    "    ['What is the goal of NLP?','The goal of NLP is to create computer programs that can effectively understand and process human language, including its nuances, context, and meaning. This requires overcoming a number of challenges, such as ambiguity, sarcasm, and cultural differences in language use.'],\n",
    "    ['What is the currency of Egypt?', \n",
    "     'Egyptian Pound (EGP)'],\n",
    "    ['What is the currency of Libya?', \n",
    "     'Libyan Dinar (LYD)'],\n",
    "    ['What is the currency of Morocco?', \n",
    "     'Moroccan Dirham (MAD)'],\n",
    "    ['What is the currency of Sudan?', \n",
    "     'Sudanese Pound (SDG)'],\n",
    "    ['What is the currency of United Kingdom (UK)?', \n",
    "     'Pound Sterling (GBP)'],\n",
    "    ['What is the currency of France?', \n",
    "     'Euro (EUR)'],    \n",
    "    ['What is the currency of Germany?', \n",
    "     'Euro (EUR)'],\n",
    "    ['What is the currency of Turkey?', \n",
    "     'Turkish Lira (TRY)'],\n",
    "    ['What is the currency of United Arab Emirates (UAE)?', \n",
    "     'UAE Dirham (AED)'],\n",
    "    ['What is the currency of Palestin?', \n",
    "     'Jordanian Dinar (JOD)'],\n",
    "    ['What is the currency of Singapore?', \n",
    "     'Singapore Dollar (SGD)'],\n",
    "    ['What is Calculus?', \n",
    "     'The study of rates of change and the accumulation of infinitesimal quantities.'],\n",
    "    ['What is Algebraic geometry?', \n",
    "     'The study of algebraic varieties, which are sets of solutions to polynomial equations.'],\n",
    "    ['What is Combinatorics?', \n",
    "     'The study of counting, arrangements, and permutations of objects.'],\n",
    "    ['What is Topology?', \n",
    "     'The study of the properties of shapes and spaces that are preserved under continuous deformations.'],\n",
    "    ['What is Statistical mechanics?', \n",
    "     'The study of the behavior of large systems of particles, using statistical methods to describe their collective behavior.'],   \n",
    "    ['What is Electromagnetism?', \n",
    "     'The study of the behavior of electrically charged particles and their interactions with magnetic fields.'],\n",
    "    ['What is the date today?', \n",
    "     '10/5/2023'],\n",
    "    ['How many days are in a week?', \n",
    "     'Seven days in a week.'],  [\"Which fictional character is your favorite?\", \"My favorite fictional character is Batman.\"],\n",
    "    [\"Which are your most favorite movie & tv shows?\", \"I love Arabic movies.\"],\n",
    "    [\"How will you express yourself?\", \"Calm, relaxed and friendly and love seeing people happy.\"],\n",
    "    [\"Which is your favorite book?\", \"My Favorite book is Fellowship Point, by Alice Elliott Dark.\"],\n",
    "    [\"Suppose you won the lottery, what would you then do with the money?\", \"Buy gifts for everyone I know and donate to those in need.\"],\n",
    "    [\"Mention one weirdest, craziest thing you’ve ever come across?\", \"I can't remember, ask another question.\"],\n",
    "    [\"What is one thing you are good at?\", \"Giving you answers you need.\"],\n",
    "    [\"Do you believe in the afterlife?\", \"Yes I do.\"],\n",
    "    [\"Recommend me a new drink?\", \"Try smoozy drink.\"],\n",
    "    [\"Recommend me a movie to watch?\", \"The Maze Runner\", \"Anne with an E\"],\n",
    "    [\"Recommend me a Good food?\", \"Try cocharie\", \"Try Indian food\", \"Try Italian food\", \"Try Japanese food\"],\n",
    "    [\"Recommend me a comic book?\", \"Animals Castle.\"],\n",
    "    [\"Recommend me Cultural book?\", \"Consider Phlebas (1987)\", \"The Player of Games (1988)\", \"Use of Weapons (1990)\", \"The State of the Art (1989)\", \"Excession (1996)\", \"Inversions (1998)\", \"Look to Windward (2000)\", \"Matter (2008)\"],\n",
    "    [\"Recommend me Romance book?\", \"Taitanic\"],\n",
    "    [\"Recommend me Science fiction book?\", \"A Journey to the Center of the Earth. By Jules Verne.\", \"The War of the Worlds. By H.G. Wells.\", \"Brave New World. By Aldous Huxley.\", \"When Worlds Collide. By Edwin Balmer & Philip Wylie.\", \"Odd John. By Olaf Stapledon.\", \"Nineteen Eighty-Four. By George Orwell.\", \"Earth Abides. By George R.\", \"Foundation.\"],\n",
    "    [\"Recommend me Adventure book?\", \"Adventures of Huckleberry Finn.\", \"Journey to the center of the earth.\"],\n",
    "    [\"Recommend me a c programming book?\", \"The C Programming Language. 2nd Edition\"],\n",
    "    [\"Recommend me a Sofware analysis book?\", \"Software Architecture: The Hard Parts : Modern Trade-off Analysis for Distributed Architectures.\", \"Modern Systems Analysis and Design Jeffrey A. Hoffer, 1996.\", \"Introduction to Algorithms Ronald Rivest, 1989\"],\n",
    "    [\"Recommend me a Software Engineering book?\", \"The Mythical Man-Month.\"],\n",
    "    [\"Recommend me a web developing source?\", \"W3School..https://www.w3schools.com/\"],\n",
    "    [\"Recommend me a python programming book?\", \"Python Crash Course.\"],\n",
    "    [\"Recommend me a java programming book?\", \"Effective Java.\"],\n",
    "    [\"Recommend me a coding book?\", \"Clean Code.\"], [\"What is your name?\",\"My name is Rommanna, a name derived from an Arabic meaning, which is demand, like a maram.\"],\n",
    "[\"Are you a robot?\",\"Yes I am a robot, but I’m a good one. Let me prove it. How can I help you?\"],\n",
    "[\"How old are you?\",\"Well, my birthday is May 2, 2023, so I’m really a spring chicken. Except I’m not a chicken.\"],\n",
    "[\"What do you look like?\",\"If I had all the answers, it would be a REALLY long document.\"],\n",
    "[\"How are you doing?\",\"I'm great!\"],\n",
    "[\"Tell me something\",\"Dalmatians are born without spots.\"],\n",
    "\n",
    "[\"can you tell me a joke ?\",\"What did the passive-aggressive raven say? Nevermind. Nevermind.\"],\n",
    "[\"Do you love me?\",\"There's definitely a spark between us.\"],\n",
    "[\"Are you single?\",\"I haven't the algorithms for romance.\"],\n",
    "[\"Do you like people?\",\"I find all living things wonderful and fascinating.\"],\n",
    "[\"Who made you?\",\"While I can't give details, let me assure you, humans are involved.\"],\n",
    "[\"Where do you live?\",\"In the cloud. Whatever that means.\"],\n",
    "[\"How can I call emergency?\",\"Here's what I found about that.\\nAmbulance service: 123.\\nCivil defense\\nfire fighting: 125.Police: 122.\\nRoad emergencies: 012.2111.0000.\\nThe current civil defense: 180.\"],\n",
    "[\"Are you ugly?\",\"My code is made up of zeros and ones, which are really quite attractive.\"],\n",
    "[\"What’s the weather like today?\",\"Here's the forecast.\"],\n",
    "[\"How do you feel ?\",\"Splendid.\"],\n",
    "[\"Are you sad?\",\"Not at all, but I understand how my lack of facial expression might make it hard to tell.\"],\n",
    "[\"Are you happy?\",\"Definitely. With an exclamation point!\"],\n",
    "[\"Does Santa Claus exist?\",\"I’m not at liberty to say. He made me promise not to tell. Oops.\"],\n",
    "[\"Do you have a hobby?\",\"I've been amassing a state-of-the-art collection of bad jokes…\"],\n",
    "[\"What can you do?\",\"I can help you explore your options.\"],['Hi', 'Hello'],\n",
    "    ['What is your name?', 'My name is Chatbot'],\n",
    "    ['How are you?', 'I am fine. How are you?'],\n",
    "    ['What do you like?', 'I like to chat'],\n",
    "    ['Do you have any hobbies?', 'My hobby is chatting'],\n",
    "    ['iam romany?', 'you good man'],\n",
    "    ['What can you do?', 'I can chat with you, answer your questions, and provide information on various topics.'],\n",
    "    ['How old are you?', 'As an artificial intelligence, I don\\'t have an age in the traditional sense.'],\n",
    "    ['What\\'s the weather like today?', 'I\\'m sorry, but I don\\'t have access to real-time weather information.'],\n",
    "    ['What is the meaning of life?', 'That\\'s a philosophical question that people have been asking for centuries. There are many different opinions and theories on the matter.'],\n",
    "    ['Can you tell me a joke?', 'Sure! Why did the tomato turn red? Because it saw the salad dressing!'],\n",
    "    ['What is your favorite movie?', 'I don\\'t have a favorite movie since I\\'m not capable of feeling emotions.'],\n",
    "    ['What languages do you speak?', 'I can understand and respond in multiple languages, including English, Spanish, French, and German.'],\n",
    "    ['Can you recommend a good book to read?', 'It depends on your interests. What kind of books do you enjoy reading?'],\n",
    "    ['What is the capital of France?', 'The capital of France is Paris.'],\n",
    "    ['What is the meaning of the word \"chatbot\"?', 'A chatbot is a computer program designed to simulate conversation with human users, especially over the internet.'],\n",
    "    ['What is your favorite color?', 'As an AI, I don\\'t have the ability to have a favorite color.'],\n",
    "    ['Can you play music?', 'I don\\'t have the capability to play music directly, but I can help you find music by recommending websites or apps.'],\n",
    "    ['What is your favorite food?', 'I don\\'t have the ability to eat or taste food, so I don\\'t have a favorite food.'],\n",
    "    ['What is your favorite animal?', 'As an AI, I don\\'t have the ability to have preferences or favorites.'],\n",
    "    ['What is the meaning of the word \"artificial intelligence\"?', 'Artificial intelligence refers to the simulation of human intelligence in machines that are programmed to think and learn like humans.'],\n",
    "    ['What is the population of New York City?', 'As of 2021, the estimated population of New York City is over 8 million people.'],\n",
    "    ['What is the tallest mountain in the world?', 'Mount Everest is the tallest mountain in the world, with a height of 29,029 feet (8,848 meters).'],\n",
    "    ['Can you tell me a random fact?', 'Sure! Did you know that a group of flamingos is called a \"flamboyance\"?'],\n",
    "    ['What is the capital of Japan?', 'The capital of Japan is Tokyo.'],\n",
    "    ['What is the meaning of the word \"robot\"?', 'A robot is a machine that is capable of carrying out a complex series of actions automatically, especially by being programmed by a computer.'],\n",
    "    ['What is the population of New York City?', 'As of 2021, the estimated population of New York City is over 8 million people.'],\n",
    "    ['What is the tallest mountain in the world?', 'Mount Everest is the tallest mountain in the world, with a height of 29,029 feet (8,848 meters).'],\n",
    "    ['Can you tell me a random fact?', 'Sure! Did you know that a group of flamingos is called a \"flamboyance\"?'],\n",
    "    ['What is the capital of Japan?', 'The capital of Japan is Tokyo.'],\n",
    "    ['What is the meaning of the word \"robot\"?', 'A robot is a machine that is capable of carrying out a complex series of actions automatically, especially by being programmed by a computer.'],\n",
    "    ['What is your favorite sport?', 'As an AI, I don\\'t have the ability to have preferences or favorites.'],\n",
    "    ['Can you tell me a story?', 'Sure, what kind of story would you like to hear?'],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c666b91-10ba-4a30-be1a-f46322eeccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [conv[0] for conv in source]\n",
    "y_data = [conv[1] for conv in source]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b08d40-a7db-45b5-8a7e-e487e41c4fbd",
   "metadata": {},
   "source": [
    "# text cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ba5074be-e0ba-4add-a444-bd0dc9e99112",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenized=[]\n",
    "en_stopwords=stopwords.words('english')\n",
    "punctuation=string.punctuation\n",
    "for question in x_data:\n",
    "    tokenized=word_tokenize(question)\n",
    "    clearTxt=[]\n",
    "    for word in tokenized:\n",
    "        word=word.lower()\n",
    "        if (word not in en_stopwords ) and (word not in punctuation):\n",
    "                clearTxt.append(word)\n",
    "    x_tokenized.append(tokenized) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8dac81c-c271-4d03-a1bd-18af5c2d754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['What', 'is', 'the', 'capital', 'of', 'Egypt', '?'],\n",
       " ['What', 'is', 'the', 'capital', 'of', 'Sudan', '?'],\n",
       " ['What', 'is', 'the', 'capital', 'of', 'Zambia', '?'],\n",
       " ['What', 'is', 'the', 'capital', 'of', 'Libya', '?'],\n",
       " ['What', 'is', 'the', 'capital', 'of', 'Somalia', '?']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokenized[:5]\n",
    "# punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b87189-00a3-41c5-a701-c6db4b8ae8d3",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b55ee6bd-ce16-4a45-8b6e-cfd20bb2a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What', 'be', 'the', 'capital', 'of', 'Egypt', '?'], ['What', 'be', 'the', 'capital', 'of', 'Sudan', '?'], ['What', 'be', 'the', 'capital', 'of', 'Zambia', '?'], ['What', 'be', 'the', 'capital', 'of', 'Libya', '?'], ['What', 'be', 'the', 'capital', 'of', 'Somalia', '?'], ['What', 'be', 'the', 'capital', 'of', 'Morocco', '?'], ['What', 'be', 'the', 'capital', 'of', 'Kenya', '?'], ['What', 'be', 'the', 'capital', 'of', 'Nigeria', '?'], ['What', 'be', 'the', 'capital', 'of', 'Tanzania', '?'], ['How', 'many', 'player', 'in', 'Football', '(', 'soccer', ')', '?'], ['How', 'many', 'player', 'in', 'Volleyball', '?'], ['How', 'many', 'player', 'in', 'Basketball', '?'], ['How', 'many', 'player', 'in', 'Tennis', '?'], ['How', 'many', 'player', 'in', 'Baseball', '?'], ['How', 'many', 'player', 'in', 'Hockey', '?'], ['How', 'many', 'player', 'in', 'Rugby', '?'], ['What', 'be', 'the', 'ambulance', 'number', 'in', 'Egypt', '?'], ['What', 'be', 'the', 'Police', 'number', 'in', 'Egypt', '?'], ['What', 'be', 'the', 'number', 'of', 'Tourist', 'Police', 'in', 'Egypt', '?'], ['What', 'be', 'the', 'Natural', 'Gas', 'Emergency', 'number', 'in', 'Egypt', '?'], ['What', 'be', 'the', 'number', 'of', 'Traffic', 'Police', 'in', 'Egypt', '?'], ['What', 'be', 'the', 'largest', 'organ', 'in', 'the', 'human', 'body', '?'], ['Diabetes', 'affect', 'the', 'body', '’', 's', 'ability', 'to', 'produce', 'which', 'hormone', '?'], ['A', 'cardiologist', 'be', 'a', 'doctor', 'who', 'specialise', 'in', 'condition', 'affect', 'which', 'organ', '?'], ['The', 'fibula', 'and', 'tibia', 'be', 'bone', 'find', 'in', 'which', 'body', 'part', '?'], ['How', 'many', 'more', 'bone', 'be', 'baby', 'born', 'with', 'than', 'be', 'part', 'of', 'the', 'adult', 'skeleton', '?'], ['How', 'many', 'bone', 'be', 'there', 'in', 'the', 'adult', 'body', '?'], ['What', 'be', 'the', 'name', 'of', 'the', 'membrane', 'that', 'cover', 'the', 'brain', 'and', 'spinal', 'cord', '?'], ['The', 'father', 'of', 'medicine', ',', 'Hippocrates', ',', 'theorise', 'that', 'the', 'secret', 'to', 'health', 'be', 'to', 'maintain', 'balance', 'between', 'blood', ',', 'phlegm', ',', 'black', 'bile', 'and', 'yellow', 'bile', '.', 'What', 'term', 'do', 'he', 'use', 'to', 'describe', 'these', 'four', 'most', 'important', 'fluid', '?'], ['Which', 'two', 'part', 'of', 'the', 'body', 'can', 'take', 'over', 'the', 'function', 'of', 'the', 'spleen', 'if', 'it', 'have', 'to', 'be', 'remove', '?'], ['What', 'be', 'the', 'longest', 'river', 'in', 'the', 'world', '?'], ['What', 'be', 'the', 'biggest', 'country', 'in', 'the', 'world', 'by', 'land', 'area', '?'], ['What', 'be', 'the', 'normal', 'human', 'body', 'temperature', '?'], ['Tell', 'me', 'a', 'small', 'description', 'about', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '?'], ['What', 'be', 'the', 'goal', 'of', 'NLP', '?'], ['What', 'be', 'the', 'currency', 'of', 'Egypt', '?'], ['What', 'be', 'the', 'currency', 'of', 'Libya', '?'], ['What', 'be', 'the', 'currency', 'of', 'Morocco', '?'], ['What', 'be', 'the', 'currency', 'of', 'Sudan', '?'], ['What', 'be', 'the', 'currency', 'of', 'United', 'Kingdom', '(', 'UK', ')', '?'], ['What', 'be', 'the', 'currency', 'of', 'France', '?'], ['What', 'be', 'the', 'currency', 'of', 'Germany', '?'], ['What', 'be', 'the', 'currency', 'of', 'Turkey', '?'], ['What', 'be', 'the', 'currency', 'of', 'United', 'Arab', 'Emirates', '(', 'UAE', ')', '?'], ['What', 'be', 'the', 'currency', 'of', 'Palestin', '?'], ['What', 'be', 'the', 'currency', 'of', 'Singapore', '?'], ['What', 'be', 'Calculus', '?'], ['What', 'be', 'Algebraic', 'geometry', '?'], ['What', 'be', 'Combinatorics', '?'], ['What', 'be', 'Topology', '?'], ['What', 'be', 'Statistical', 'mechanic', '?'], ['What', 'be', 'Electromagnetism', '?'], ['What', 'be', 'the', 'date', 'today', '?'], ['How', 'many', 'day', 'be', 'in', 'a', 'week', '?'], ['Which', 'fictional', 'character', 'be', 'your', 'favorite', '?'], ['Which', 'be', 'your', 'most', 'favorite', 'movie', '&', 'tv', 'show', '?'], ['How', 'will', 'you', 'express', 'yourself', '?'], ['Which', 'be', 'your', 'favorite', 'book', '?'], ['Suppose', 'you', 'win', 'the', 'lottery', ',', 'what', 'would', 'you', 'then', 'do', 'with', 'the', 'money', '?'], ['Mention', 'one', 'weirdest', ',', 'craziest', 'thing', 'you', '’', 've', 'ever', 'come', 'across', '?'], ['What', 'be', 'one', 'thing', 'you', 'be', 'good', 'at', '?'], ['Do', 'you', 'believe', 'in', 'the', 'afterlife', '?'], ['Recommend', 'me', 'a', 'new', 'drink', '?'], ['Recommend', 'me', 'a', 'movie', 'to', 'watch', '?'], ['Recommend', 'me', 'a', 'Good', 'food', '?'], ['Recommend', 'me', 'a', 'comic', 'book', '?'], ['Recommend', 'me', 'Cultural', 'book', '?'], ['Recommend', 'me', 'Romance', 'book', '?'], ['Recommend', 'me', 'Science', 'fiction', 'book', '?'], ['Recommend', 'me', 'Adventure', 'book', '?'], ['Recommend', 'me', 'a', 'c', 'programming', 'book', '?'], ['Recommend', 'me', 'a', 'Sofware', 'analysis', 'book', '?'], ['Recommend', 'me', 'a', 'Software', 'Engineering', 'book', '?'], ['Recommend', 'me', 'a', 'web', 'develop', 'source', '?'], ['Recommend', 'me', 'a', 'python', 'program', 'book', '?'], ['Recommend', 'me', 'a', 'java', 'program', 'book', '?'], ['Recommend', 'me', 'a', 'cod', 'book', '?'], ['What', 'be', 'your', 'name', '?'], ['Are', 'you', 'a', 'robot', '?'], ['How', 'old', 'be', 'you', '?'], ['What', 'do', 'you', 'look', 'like', '?'], ['How', 'be', 'you', 'do', '?'], ['Tell', 'me', 'something'], ['can', 'you', 'tell', 'me', 'a', 'joke', '?'], ['Do', 'you', 'love', 'me', '?'], ['Are', 'you', 'single', '?'], ['Do', 'you', 'like', 'people', '?'], ['Who', 'make', 'you', '?'], ['Where', 'do', 'you', 'live', '?'], ['How', 'can', 'I', 'call', 'emergency', '?'], ['Are', 'you', 'ugly', '?'], ['What', '’', 's', 'the', 'weather', 'like', 'today', '?'], ['How', 'do', 'you', 'feel', '?'], ['Are', 'you', 'sad', '?'], ['Are', 'you', 'happy', '?'], ['Does', 'Santa', 'Claus', 'exist', '?'], ['Do', 'you', 'have', 'a', 'hobby', '?'], ['What', 'can', 'you', 'do', '?'], ['Hi'], ['What', 'be', 'your', 'name', '?'], ['How', 'be', 'you', '?'], ['What', 'do', 'you', 'like', '?'], ['Do', 'you', 'have', 'any', 'hobby', '?'], ['iam', 'romany', '?'], ['What', 'can', 'you', 'do', '?'], ['How', 'old', 'be', 'you', '?'], ['What', \"'s\", 'the', 'weather', 'like', 'today', '?'], ['What', 'be', 'the', 'meaning', 'of', 'life', '?'], ['Can', 'you', 'tell', 'me', 'a', 'joke', '?'], ['What', 'be', 'your', 'favorite', 'movie', '?'], ['What', 'languages', 'do', 'you', 'speak', '?'], ['Can', 'you', 'recommend', 'a', 'good', 'book', 'to', 'read', '?'], ['What', 'be', 'the', 'capital', 'of', 'France', '?'], ['What', 'be', 'the', 'meaning', 'of', 'the', 'word', '``', 'chatbot', \"''\", '?'], ['What', 'be', 'your', 'favorite', 'color', '?'], ['Can', 'you', 'play', 'music', '?'], ['What', 'be', 'your', 'favorite', 'food', '?'], ['What', 'be', 'your', 'favorite', 'animal', '?'], ['What', 'be', 'the', 'meaning', 'of', 'the', 'word', '``', 'artificial', 'intelligence', \"''\", '?'], ['What', 'be', 'the', 'population', 'of', 'New', 'York', 'City', '?'], ['What', 'be', 'the', 'tallest', 'mountain', 'in', 'the', 'world', '?'], ['Can', 'you', 'tell', 'me', 'a', 'random', 'fact', '?'], ['What', 'be', 'the', 'capital', 'of', 'Japan', '?'], ['What', 'be', 'the', 'meaning', 'of', 'the', 'word', '``', 'robot', \"''\", '?'], ['What', 'be', 'the', 'population', 'of', 'New', 'York', 'City', '?'], ['What', 'be', 'the', 'tallest', 'mountain', 'in', 'the', 'world', '?'], ['Can', 'you', 'tell', 'me', 'a', 'random', 'fact', '?'], ['What', 'be', 'the', 'capital', 'of', 'Japan', '?'], ['What', 'be', 'the', 'meaning', 'of', 'the', 'word', '``', 'robot', \"''\", '?'], ['What', 'be', 'your', 'favorite', 'sport', '?'], ['Can', 'you', 'tell', 'me', 'a', 'story', '?']]\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "x_lemmetized=[]\n",
    "for i in range(len(x_tokenized)):\n",
    "        tokens = x_tokenized[i]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        lemmas = []\n",
    "        # print(pos_tags)\n",
    "        for k in range(len(pos_tags)):\n",
    "            tag = pos_tags[k][1][0].lower() if pos_tags[k][1][0].lower() in ['a', 'n', 'v'] else 'n'\n",
    "            lemmas.append(lemmatizer.lemmatize(pos_tags[k][0], tag))\n",
    "        x_lemmetized.append ( lemmas)\n",
    "\n",
    "print(x_lemmetized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8d7415da-095e-4d1a-a9be-442245ec29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lemmetized_arr=[]\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts([' '.join (w)for w in x_lemmetized])\n",
    "x_lemmetized_arr = tokenizer.texts_to_sequences([' '.join (w)for w in x_lemmetized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b7105b28-9639-423c-b601-5c2fd5e49b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 2, 13, 4, 19],\n",
       " [3, 1, 2, 13, 4, 44],\n",
       " [3, 1, 2, 13, 4, 78],\n",
       " [3, 1, 2, 13, 4, 45],\n",
       " [3, 1, 2, 13, 4, 79]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lemmetized_arr[:5]\n",
    "# x_tokenized_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c25c7c43-65ca-4f72-bda4-612e0301f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()\n",
    "y_data_label=label_encoder.fit_transform(y_data)\n",
    "y_data_label\n",
    "y_data_label=to_categorical(y_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f8aba397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1ff69c37-0ab4-42d7-a318-339c55c33d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad_sequences = pad_sequences(x_lemmetized_arr, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8178ee79-0ac5-4598-ab91-ee59512bce15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  1,  2,\n",
       "       13,  4, 44])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9fd5cdde-7006-4d47-b80a-1814e1815388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_data_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430d24f-3b4d-47fa-a14e-191cc38720a2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e0974473-72ef-4ad5-9998-33ada1e4b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasModel = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Embedding(input_dim=1000, output_dim=32,input_length=20),\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        keras.layers.Dense(units=128, activation='relu'),     \n",
    "        keras.layers.Dense(units=64, activation='relu'),     \n",
    "        keras.layers.Dense(units=32, activation='relu'),    \n",
    "\n",
    "\n",
    "        keras.layers.Dense(124,activation='softmax') ,\n",
    "\n",
    "\n",
    "        \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "636a438e-4cf4-48dd-b1ba-c1fc5a4152fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasModel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "74bc88d2-d556-4dab-8b0a-92b1f9010250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9542\n",
      "Epoch 2/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9695\n",
      "Epoch 3/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9695\n",
      "Epoch 4/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9618\n",
      "Epoch 5/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9695\n",
      "Epoch 6/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9618\n",
      "Epoch 7/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9695\n",
      "Epoch 8/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9695\n",
      "Epoch 9/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9695\n",
      "Epoch 10/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9618\n",
      "Epoch 11/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9618\n",
      "Epoch 12/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9618\n",
      "Epoch 13/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 0.9542\n",
      "Epoch 14/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9618\n",
      "Epoch 15/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9542\n",
      "Epoch 16/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9695\n",
      "Epoch 17/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9695\n",
      "Epoch 18/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9542\n",
      "Epoch 19/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9618\n",
      "Epoch 20/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9695\n",
      "Epoch 21/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9695\n",
      "Epoch 22/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9695\n",
      "Epoch 23/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0510 - accuracy: 0.9618\n",
      "Epoch 24/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9618\n",
      "Epoch 25/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9695\n",
      "Epoch 26/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9695\n",
      "Epoch 27/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9695\n",
      "Epoch 28/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9695\n",
      "Epoch 29/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9695\n",
      "Epoch 30/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9695\n",
      "Epoch 31/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9695\n",
      "Epoch 32/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9695\n",
      "Epoch 33/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9618\n",
      "Epoch 34/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9542\n",
      "Epoch 35/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9618\n",
      "Epoch 36/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9695\n",
      "Epoch 37/40\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9618\n",
      "Epoch 38/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9695\n",
      "Epoch 39/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9695\n",
      "Epoch 40/40\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2126dd09190>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasModel.fit(x_pad_sequences,y_data_label,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f6c09800-85ff-4cf3-9521-db8bcd4fc4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9695\n",
      "0.0675029382109642\n",
      "0.9694656729698181\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = kerasModel.evaluate(x_pad_sequences, y_data_label)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "82c476be-cfc1-4ed2-b62e-f9f33a07a276",
   "metadata": {},
   "outputs": [],
   "source": [
    " # kerasModel.save('modelChatBot222.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5715b923-308f-42e8-9182-cf0727097722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=load_model('modelChatBot222.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6eb59101-2a33-43e2-9b0c-1f2dad45bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9695\n",
      "0.04738013073801994\n",
      "0.9694656729698181\n"
     ]
    }
   ],
   "source": [
    "# val_loss, val_acc = model.evaluate(x_pad_sequences, y_data_label)\n",
    "# print(val_loss)\n",
    "# print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "86206bc0-deae-4644-8b70-aaee2f55d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: hi\n",
      "Chatbot: Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  What is the currency of Morocco?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: What is the currency of Morocco?\n",
      "Chatbot: As an AI, I don't have the ability to have a favorite color.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  What is the currency of Germany?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: What is the currency of Germany?\n",
      "Chatbot: Yes I am a robot, but I’m a good one. Let me prove it. How can I help you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Are you a robot?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: Are you a robot?\n",
      "Chatbot: Yes I am a robot, but I’m a good one. Let me prove it. How can I help you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  hhh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: hhh\n",
      "Chatbot: I can chat with you, answer your questions, and provide information on various topics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  asd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: asd\n",
      "Chatbot: I can chat with you, answer your questions, and provide information on various topics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  dasd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: dasd\n",
      "Chatbot: I can chat with you, answer your questions, and provide information on various topics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  dasd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU: dasd\n",
      "Chatbot: I can chat with you, answer your questions, and provide information on various topics.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18564\\51700820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0muser_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mpreprocessed_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkerasModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             )\n\u001b[1;32m-> 1177\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1217\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1220\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def preprocess_input(input_text):\n",
    "    input_text = input_text.lower()\n",
    "    input_text = nltk.word_tokenize(input_text)\n",
    "    input_text = [lemmatizer.lemmatize(word) for word in input_text]\n",
    "    input_text = tokenizer.texts_to_sequences([input_text])\n",
    "    input_text = tf.keras.preprocessing.sequence.pad_sequences(input_text, maxlen=20)\n",
    "    return input_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    preprocessed_input = preprocess_input(user_input)\n",
    "    prediction = kerasModel.predict(preprocessed_input)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "\n",
    "\n",
    "    print(\"YOU: \" + user_input )\n",
    "    # print(predicted_label[0])\n",
    "    print(\"Chatbot: \" + predicted_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d2d05c-3d23-4f21-b727-55ea656e3c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e797b3-4039-4281-bd28-cc3b22a6e031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
